apiVersion: flowctl/v1
kind: Pipeline
metadata:
  name: local-pipeline
  namespace: development
  labels:
    environment: local
    purpose: file-processing
  annotations:
    description: "Local pipeline for file-based data processing"

spec:
  description: "Example pipeline for local process execution with file I/O"
  driver: local
  
  sources:
    - id: file-watcher
      type: source
      image: alpine:latest
      command: ["sh", "-c"]
      args: |
        # Create input directory if it doesn't exist
        mkdir -p /tmp/pipeline/input
        
        # Watch for new files and emit them
        while true; do
          for file in /tmp/pipeline/input/*.json; do
            if [ -f "$file" ]; then
              echo "{\"event\": \"new_file\", \"path\": \"$file\", \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}"
              # Move processed files to prevent reprocessing
              mv "$file" "${file}.processing"
            fi
          done
          sleep 2
        done
      env:
        WATCH_DIR: "/tmp/pipeline/input"
        FILE_PATTERN: "*.json"
  
  processors:
    - id: json-validator
      type: processor
      image: alpine:latest
      command: ["sh", "-c"]
      args: |
        # Validate JSON files
        while read event; do
          file_path=$(echo "$event" | sed -n 's/.*"path": "\([^"]*\)".*/\1/p').processing
          
          if [ -f "$file_path" ]; then
            # Check if valid JSON
            if cat "$file_path" | json_pp >/dev/null 2>&1; then
              echo "{\"status\": \"valid\", \"file\": \"$file_path\", \"size\": $(stat -c%s "$file_path"), \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}"
            else
              echo "{\"status\": \"invalid\", \"file\": \"$file_path\", \"error\": \"Invalid JSON format\", \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}"
            fi
          fi
        done
      inputs: ["file-watcher"]
      env:
        VALIDATION_STRICT: "true"
    
    - id: data-transformer
      type: processor
      image: alpine:latest
      command: ["sh", "-c"]
      args: |
        # Transform valid JSON files
        mkdir -p /tmp/pipeline/transformed
        
        while read validation; do
          status=$(echo "$validation" | grep -o '"status": "[^"]*"' | cut -d'"' -f4)
          file_path=$(echo "$validation" | sed -n 's/.*"file": "\([^"]*\)".*/\1/p')
          
          if [ "$status" = "valid" ] && [ -f "$file_path" ]; then
            # Simple transformation: add metadata
            base_name=$(basename "$file_path" .json.processing)
            output_file="/tmp/pipeline/transformed/${base_name}_transformed.json"
            
            echo "{
              \"original_file\": \"$file_path\",
              \"transformed_at\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\",
              \"processor\": \"data-transformer\",
              \"data\": $(cat "$file_path")
            }" > "$output_file"
            
            echo "{\"transformed\": true, \"output\": \"$output_file\", \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}"
          else
            echo "$validation"
          fi
        done
      inputs: ["json-validator"]
      env:
        TRANSFORM_TYPE: "metadata_enrichment"
  
  sinks:
    - id: file-writer
      type: sink
      image: alpine:latest
      command: ["sh", "-c"]
      args: |
        # Write results to output directory
        mkdir -p /tmp/pipeline/output
        mkdir -p /tmp/pipeline/processed
        
        while read result; do
          timestamp=$(date +%Y%m%d_%H%M%S)
          
          # Write result to output
          echo "$result" >> "/tmp/pipeline/output/results_${timestamp}.log"
          
          # Move processed files
          file_path=$(echo "$result" | sed -n 's/.*"file": "\([^"]*\)".*/\1/p')
          if [ -f "$file_path" ]; then
            mv "$file_path" "/tmp/pipeline/processed/$(basename $file_path .processing)"
          fi
          
          echo "[FILE-SINK] Processed: $result"
        done
      inputs: ["data-transformer"]
      env:
        OUTPUT_DIR: "/tmp/pipeline/output"
        ARCHIVE_PROCESSED: "true"